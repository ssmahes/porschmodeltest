{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aantal relevante variabelen: 249\n",
      "['aanvanders', 'adenocarcinoma', 'adjudat', 'Adjudication_Committee', 'adjuvant', 'adjuvant_treatment', 'adjuvantstart', 'Age_surgery', 'albu', 'amesen', 'anadetail', 'anasinw', 'anastmaagdarm', 'anastomose', 'anasuitw', 'arthepaberrant', 'arthepcomprop', 'arthepdexacces', 'artmesent', 'ASA.high2', 'asascore', 'asascore.compl', 'aspect', 'aspect.2', 'beeldconcl', 'behperdat', 'betrahepati', 'betramesent', 'betranders', 'betrcolon', 'betrmaag', 'betrtrcoel', 'betrvcava', 'betrvporta', 'bildianastomose', 'biliarydrainage', 'biliodig', 'bilirubine', 'BMI', 'ca199', 'Cal_OK_acute_pancreatitis', 'Cal_OK_chylus2016', 'Cal_OK_fistel2016', 'Cal_OK_gallek', 'Cal_OK_GElek', 'cal_wel_geen_PPH', 'cea', 'chylus2016.castor', 'circumcontact', 'Clavien.Dindo.high', 'Clavien_dindo_I_aantal', 'Clavien_Dindo_II_aantal', 'Clavien_Dindo_IIIa_aantal', 'Clavien_Dindo_IIIb_aantal', 'Clavien_Dindo_IVa_aantal', 'Clavien_Dindo_IVb_aantal', 'coelblok', 'colonsegm', 'colont', 'combind', 'comdem', 'comdiam', 'comdiaminsu', 'comgiulcus', 'comhiv', 'comlever', 'comlong', 'commal2', 'commal3', 'commalig', 'comorbiditeiten_uri', 'component', 'contactah', 'contactams', 'contacttc', 'cox.time.to.AB', 'cox.time.to.adjuvant', 'cytdiagnose', 'datont.castor', 'datovl.castor', 'dcholedo', 'diagroot', 'diamdp', 'diameterpost', 'differentiatie', 'diffnet', 'drain', 'drain_aantal', 'drain_amylase', 'ductus.verwijd', 'ductus.verwijd.2', 'dunnedarm', 'duurok', 'ecog', 'eustumor', 'exlapzbypass', 'exploratie', 'Extra_ABstart', 'Extra_ABstart_1', 'Extra_ABstart_1_1', 'Extra_herstart', 'Extra_herstart_1', 'Extra_herstart_1_1', 'Extra_herstart_2', 'Extra_herstart_2_1', 'Extra_herstart_2_1_1', 'Extra_herstart_3', 'Extra_herstart_3_1', 'Extra_herstart_3_1_1', 'Extra_herstart_4', 'Extra_herstart_4_1', 'Extra_herstart_4_1_1', 'gastrojejuno', 'geenanders', 'gender', 'gender.castor', 'gender.dpca', 'gewicht', 'gewperiode', 'gewverlies', 'hemicolr', 'hemoglobine', 'hepatica', 'histdiagnose', 'histdiagnpost', 'histdiagnpost.compl', 'hospitalstay', 'hypotens', 'IC.days', 'id', 'igg4', 'Indication_AB_2', 'invasief', 'invasief.compl', 'ipmn', 'ipmnpost', 'kreat', 'laparoscopie', 'lapexplor', 'lengte', 'lever', 'ligahepato', 'lokalisatie', 'lymfade', 'maagontl', 'maagresec', 'malignant', 'mcicopname', 'mcneo', 'mcneopost', 'mdopostop', 'metalever', 'metalong', 'metaoverig', 'metastasen', 'nasojeju', 'neoadj_anders', 'neoadj_treatment_other', 'neoadjdat', 'neoadjuvant', 'neoadjuvant.castor', 'neoadjuvant.dpca', 'neoadjuvant.YN', 'neoadjuvant_chemo', 'netpost', 'notPDAC.or.itis', 'octreo', 'onderbinden', 'operative_bloodloss.compl', 'operative_time', 'opnameduur', 'origine', 'origine.compl', 'overhechten', 'paraortaal', 'patient_uri', 'PDAC', 'PPH_anticoagulantia', 'PPH_first_presentation', 'PPH_hemodyn_instabiel', 'PPH_origin_bleeding_spec', 'PPH_other_origin_bleeding_spec', 'PPH_plaatjesremmers', 'PPH_transfusionnumber', 'Preop_CRP', 'Preop_CRP_1', 'procoverig', 'Prolonged_AB_stop', 'radicaliteit', 'radmarge', 'reden_heropname_first', 'reden_heropname_second', 'reden_heropname_third', 'reggroep', 'resanders', 'resecaanv', 'resecart', 'resecveneus', 'responshtrg', 'risico', 'sandostat_anders', 'sandostatine', 'sandostatine_toediening.peroperatief', 'sandostatine_toediening.postoperatief', 'sandostatine_toediening.preoperatief', 'serum_amylase', 'stadptdistaal2019', 'stadptduodenum2019', 'stadptpapil2019', 'standaardokverslag', 'staplerm', 'staplerz', 'stenoseah', 'stenoseams', 'stenosevp', 'stentcover', 'structuren', 'tachosyl', 'time.since.intervention', 'time.since.intervention.norm', 'time.since.start.study.norm0', 'trcoel', 'trunccoel', 'truncuscoel', 'tumorrest', 'typeadjuvant', 'typechemothanders', 'typechemotherapy', 'typeneoadjuvant', 'typesom', 'typestent', 'typok', 'typok.dpca', 'typok_anders', 'Value_CRP', 'Value_CRP_1', 'vaten', 'venapm', 'verdikt', 'verover', 'verrichting_upn', 'verrichting_uri', 'verwijd', 'vet', 'voedjeju', 'weefsellijm', 'weefselpatch', 'Year_birth', 'Year_birth.castor']\n",
      "\n",
      "Variabelen zonder bestandsnaam:\n",
      "['adenocarcinoma', 'asascore.compl', 'aspect.2', 'chylus2016.castor', 'Clavien.Dindo.high', 'cox.time.to.AB', 'datont.castor', 'datovl.castor', 'ductus.verwijd.2', 'Extra_ABstart', 'Extra_ABstart_1', 'Extra_ABstart_1_1', 'Extra_herstart', 'Extra_herstart_1', 'Extra_herstart_1_1', 'Extra_herstart_2', 'Extra_herstart_2_1', 'Extra_herstart_2_1_1', 'Extra_herstart_3', 'Extra_herstart_3_1', 'Extra_herstart_3_1_1', 'Extra_herstart_4', 'Extra_herstart_4_1', 'Extra_herstart_4_1_1', 'gender.castor', 'gender.dpca', 'histdiagnpost.compl', 'hospitalstay', 'IC.days', 'Indication_AB_2', 'invasief.compl', 'malignant', 'neoadjuvant.castor', 'neoadjuvant.dpca', 'neoadjuvant.YN', 'operative_bloodloss.compl', 'origine.compl', 'Preop_CRP', 'Preop_CRP_1', 'Prolonged_AB_stop', 'sandostatine_toediening.peroperatief', 'sandostatine_toediening.postoperatief', 'sandostatine_toediening.preoperatief', 'time.since.start.study.norm0', 'Value_CRP', 'Value_CRP_1', 'Year_birth.castor']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Lees de data dictionary\n",
    "data_dict = pd.read_excel(r'C:\\Users\\sanma\\Downloads\\PORSCH\\nieuwe_data_dictionary.xlsx')\n",
    "\n",
    "# Selecteer relevante variabelen (categorisch, input, meenemen)\n",
    "relevante_vars = data_dict[(data_dict['Soort data (0=onbekend, 1=continue, 2=categorisch)'] == 2) & \n",
    "                           (data_dict['0=input, 1=output, 2=onbekend'] == 0) & \n",
    "                           (data_dict['Meenemen (0=nee, 1= ja, 2=onbekend, 3=computatie)'] == 1)]\n",
    "\n",
    "print(f\"Aantal relevante variabelen: {len(relevante_vars)}\")\n",
    "print(relevante_vars['Variable name'].tolist())\n",
    "\n",
    "# Controleer variabelen zonder bestandsnaam\n",
    "vars_zonder_bestand = relevante_vars[relevante_vars['Bestandsnaam'].isna()]\n",
    "print(\"\\nVariabelen zonder bestandsnaam:\")\n",
    "print(vars_zonder_bestand['Variable name'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Functie om patiÃ«nt-ID kolom te identificeren\n",
    "def get_patient_id_column(df):\n",
    "    possible_id_columns = ['Record.Id', 'Record Id', 'VoorschriftId', 'PatientID']\n",
    "    for col in possible_id_columns:\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "# Map met bronbestanden\n",
    "bronmap = r\"C:\\Users\\sanma\\Downloads\\PORSCH\\PORSCH pancreas map\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def read_csv_safely(file_path):\n",
    "    encodings = ['utf-8', 'iso-8859-1', 'windows-1252']\n",
    "    separators = [',', ';', '\\t', '|']\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        for sep in separators:\n",
    "            try:\n",
    "                return pd.read_csv(file_path, encoding=encoding, sep=sep, low_memory=False)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    print(f\"Kon het bestand niet lezen: {file_path}\")\n",
    "    return None\n",
    "\n",
    "def get_patient_id_column(df):\n",
    "    possible_id_columns = ['Record.Id', 'Record Id', 'VoorschriftId', 'PatientID']\n",
    "    for col in possible_id_columns:\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "bronmap = r\"C:\\Users\\sanma\\Downloads\\PORSCH\\PORSCH pancreas map\"\n",
    "\n",
    "# Verzamel alle relevante data\n",
    "all_data = []\n",
    "\n",
    "for _, row in relevante_vars.iterrows():\n",
    "    if pd.notna(row['Bestandsnaam']):\n",
    "        bestandsnamen = row['Bestandsnaam'].split(', ')\n",
    "        for bestandsnaam in bestandsnamen:\n",
    "            bestandspad = os.path.join(bronmap, bestandsnaam)\n",
    "            if os.path.exists(bestandspad):\n",
    "                df = read_csv_safely(bestandspad)\n",
    "                if df is not None:\n",
    "                    id_column = get_patient_id_column(df)\n",
    "                    if id_column and row['Variable name'] in df.columns:\n",
    "                        temp_df = df[[id_column, row['Variable name']]].copy()\n",
    "                        temp_df.columns = ['PatientID', f\"{row['Variable name']}_{bestandsnaam}\"]\n",
    "                        all_data.append(temp_df)\n",
    "\n",
    "def process_data_in_chunks(data_list, chunk_size=100):\n",
    "    if not data_list:\n",
    "        raise ValueError(\"Geen data gevonden om te combineren.\")\n",
    "    \n",
    "    result = data_list[0]\n",
    "    for df in data_list[1:]:\n",
    "        unique_ids = pd.concat([result['PatientID'], df['PatientID']]).unique()\n",
    "        chunks = np.array_split(unique_ids, max(1, len(unique_ids) // chunk_size))\n",
    "        \n",
    "        new_result = pd.DataFrame()\n",
    "        for chunk in chunks:\n",
    "            result_chunk = result[result['PatientID'].isin(chunk)]\n",
    "            df_chunk = df[df['PatientID'].isin(chunk)]\n",
    "            merged_chunk = pd.merge(result_chunk, df_chunk, on='PatientID', how='outer')\n",
    "            new_result = pd.concat([new_result, merged_chunk], ignore_index=True)\n",
    "        \n",
    "        result = new_result\n",
    "        \n",
    "        # Vrij geheugen op\n",
    "        del new_result\n",
    "        import gc\n",
    "        gc.collect()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Verwerk data in chunks\n",
    "input_data = process_data_in_chunks(all_data)\n",
    "\n",
    "# Verwijder dubbele kolommen\n",
    "input_data = input_data.loc[:, ~input_data.columns.duplicated()]\n",
    "\n",
    "# Identificeer dubbele patiÃ«nt-ID's\n",
    "duplicate_counts = input_data['PatientID'].value_counts()\n",
    "max_duplicates = duplicate_counts.max()\n",
    "\n",
    "# Maak een Excel schrijver object\n",
    "excel_writer = pd.ExcelWriter(r'C:\\Users\\sanma\\Downloads\\PORSCH\\input_data.xlsx', engine='openpyxl')\n",
    "\n",
    "# Schrijf de hoofddata (eerste voorkomen van elke patiÃ«nt)\n",
    "input_data.drop_duplicates(subset=['PatientID'], keep='first').to_excel(excel_writer, sheet_name='Hoofddata', index=False)\n",
    "\n",
    "# Schrijf dubbele gegevens naar aparte bladen\n",
    "for i in range(2, max_duplicates + 1):\n",
    "    duplicate_ids = duplicate_counts[duplicate_counts >= i].index\n",
    "    duplicate_data = input_data[input_data['PatientID'].isin(duplicate_ids)].drop_duplicates(subset=['PatientID'], keep='last')\n",
    "    if not duplicate_data.empty:\n",
    "        duplicate_data.to_excel(excel_writer, sheet_name=f'Dubbele_Data_{i}', index=False)\n",
    "    input_data = input_data[~input_data['PatientID'].isin(duplicate_ids)]\n",
    "\n",
    "# Sla het Excel bestand op\n",
    "excel_writer.save()\n",
    "print(f\"Data opgeslagen in {excel_writer.path}\")\n",
    "\n",
    "# Analyseer missing data in de hoofddata\n",
    "main_data = pd.read_excel(r'C:\\Users\\sanma\\Downloads\\PORSCH\\input_data.xlsx', sheet_name='Hoofddata')\n",
    "missing_percentages = main_data.isnull().mean() * 100\n",
    "\n",
    "# Toon kolommen met meer dan 50% missing data\n",
    "high_missing = missing_percentages[missing_percentages > 50].sort_values(ascending=False)\n",
    "print(\"Kolommen met meer dan 50% missing data:\")\n",
    "print(high_missing)\n",
    "\n",
    "# Verwijder kolommen met meer dan 50% missing data, behalve de ID kolom\n",
    "columns_to_drop = high_missing.index.drop('PatientID', errors='ignore')\n",
    "input_data_clean = main_data.drop(columns=columns_to_drop)\n",
    "input_data_clean.to_excel(r'C:\\Users\\sanma\\Downloads\\PORSCH\\input_data_clean.xlsx', index=False)\n",
    "print(f\"Opgeschoonde input data opgeslagen met {len(input_data_clean.columns)} kolommen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolomnamen in de data dictionary:\n",
      "Index(['Variable name', 'Field label', 'Variable Value',\n",
      "       'Meenemen (0=nee, 1= ja, 2=onbekend, 3=computatie)',\n",
      "       '0=input, 1=output, 2=onbekend', 'Opmerkingen', 'Potentiele interactie',\n",
      "       'Computatie nodig',\n",
      "       'Soort data (0=onbekend, 1=continue, 2=categorisch)', 'Bestandsnaam'],\n",
      "      dtype='object')\n",
      "Aantal relevante variabelen: 249\n",
      "Data opgeslagen in SQLite database.\n",
      "Kolommen met meer dan 80% missing data:\n",
      "aanvanders_data.full.DCPAincluded.csv                       100.0\n",
      "notPDAC.or.itis_data.full.DCPAincluded.csv                  100.0\n",
      "origine_data.full.DCPAincluded.csv                          100.0\n",
      "operative_time_PORSCH_export_20210329.csv                   100.0\n",
      "operative_time_data.full.DCPAincluded_aangepast.csv         100.0\n",
      "                                                            ...  \n",
      "component_data.full.DCPAincluded.csv                        100.0\n",
      "comorbiditeiten_uri_data.full.DCPAincluded_aangepast.csv    100.0\n",
      "comorbiditeiten_uri_data.full.DCPAincluded.csv              100.0\n",
      "commalig_data.full.DCPAincluded_aangepast.csv               100.0\n",
      "Year_birth_data.full.DCPAincluded.csv                       100.0\n",
      "Length: 376, dtype: float64\n",
      "Opgeschoonde input data opgeslagen met 4 kolommen.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "def read_csv_safely(file_path):\n",
    "    encodings = ['utf-8', 'iso-8859-1', 'windows-1252']\n",
    "    separators = [',', ';', '\\t', '|']\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        for sep in separators:\n",
    "            try:\n",
    "                return pd.read_csv(file_path, encoding=encoding, sep=sep, low_memory=False)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    print(f\"Kon het bestand niet lezen: {file_path}\")\n",
    "    return None\n",
    "\n",
    "def get_patient_id_column(df):\n",
    "    possible_id_columns = ['Record.Id', 'Record Id', 'VoorschriftId', 'PatientID']\n",
    "    for col in possible_id_columns:\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "def column_exists(cursor, table_name, column_name):\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    return any(row[1] == column_name for row in cursor.fetchall())\n",
    "\n",
    "# Lees de data dictionary\n",
    "data_dict = pd.read_excel(r'C:\\Users\\sanma\\Downloads\\PORSCH\\nieuwe_data_dictionary.xlsx')\n",
    "\n",
    "# Print de kolomnamen om te zien wat we hebben\n",
    "print(\"Kolomnamen in de data dictionary:\")\n",
    "print(data_dict.columns)\n",
    "\n",
    "# Zoek de juiste kolomnamen\n",
    "soort_data_col = 'Soort data (0=onbekend, 1=continue, 2=categorisch)'\n",
    "input_output_col = '0=input, 1=output, 2=onbekend'\n",
    "meenemen_col = 'Meenemen (0=nee, 1= ja, 2=onbekend, 3=computatie)'\n",
    "\n",
    "# Selecteer relevante variabelen (categorisch, input, meenemen)\n",
    "relevante_vars = data_dict[(data_dict[soort_data_col] == 2) & \n",
    "                           (data_dict[input_output_col] == 0) & \n",
    "                           (data_dict[meenemen_col] == 1)]\n",
    "\n",
    "print(f\"Aantal relevante variabelen: {len(relevante_vars)}\")\n",
    "\n",
    "bronmap = r\"C:\\Users\\sanma\\Downloads\\PORSCH\\PORSCH pancreas map\"\n",
    "\n",
    "# Maak een SQLite database\n",
    "conn = sqlite3.connect(r'C:\\Users\\sanma\\Downloads\\PORSCH\\porsch_data.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Maak een tabel voor de hoofddata\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS hoofddata\n",
    "(PatientID TEXT PRIMARY KEY)\n",
    "''')\n",
    "\n",
    "# Verwerk de data\n",
    "for _, row in relevante_vars.iterrows():\n",
    "    if pd.notna(row['Bestandsnaam']):\n",
    "        bestandsnamen = row['Bestandsnaam'].split(', ')\n",
    "        for bestandsnaam in bestandsnamen:\n",
    "            bestandspad = os.path.join(bronmap, bestandsnaam)\n",
    "            if os.path.exists(bestandspad):\n",
    "                df = read_csv_safely(bestandspad)\n",
    "                if df is not None:\n",
    "                    id_column = get_patient_id_column(df)\n",
    "                    if id_column and row['Variable name'] in df.columns:\n",
    "                        # Voeg de kolom toe aan de tabel als deze nog niet bestaat\n",
    "                        column_name = f\"{row['Variable name']}_{bestandsnaam}\"\n",
    "                        if not column_exists(cursor, 'hoofddata', column_name):\n",
    "                            cursor.execute(f\"ALTER TABLE hoofddata ADD COLUMN '{column_name}' TEXT\")\n",
    "                        \n",
    "                        # Update de data in de tabel\n",
    "                        for _, data_row in df.iterrows():\n",
    "                            patient_id = data_row[id_column]\n",
    "                            value = data_row[row['Variable name']]\n",
    "                            cursor.execute(f'''\n",
    "                            INSERT OR REPLACE INTO hoofddata (PatientID, '{column_name}')\n",
    "                            VALUES (?, ?)\n",
    "                            ''', (patient_id, value))\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "# Sluit de database verbinding\n",
    "conn.close()\n",
    "\n",
    "print(\"Data opgeslagen in SQLite database.\")\n",
    "\n",
    "# Analyseer missing data\n",
    "conn = sqlite3.connect(r'C:\\Users\\sanma\\Downloads\\PORSCH\\porsch_data.db')\n",
    "main_data = pd.read_sql_query(\"SELECT * FROM hoofddata\", conn)\n",
    "conn.close()\n",
    "\n",
    "missing_percentages = main_data.isnull().mean() * 100\n",
    "\n",
    "# Toon kolommen met meer dan ..% missing data\n",
    "high_missing = missing_percentages[missing_percentages > 99].sort_values(ascending=False)\n",
    "print(\"Kolommen met meer dan 80% missing data:\")\n",
    "print(high_missing)\n",
    "\n",
    "# Verwijder kolommen met meer dan ..% missing data, behalve de ID kolom\n",
    "columns_to_keep = ['PatientID'] + list(missing_percentages[missing_percentages <= 99].index)\n",
    "input_data_clean = main_data[columns_to_keep]\n",
    "\n",
    "# Sla de opgeschoonde data op in een nieuw Excel bestand\n",
    "input_data_clean.to_excel(r'C:\\Users\\sanma\\Downloads\\PORSCH\\input_data_clean.xlsx', index=False)\n",
    "print(f\"Opgeschoonde input data opgeslagen met {len(input_data_clean.columns)} kolommen.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "porsch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
